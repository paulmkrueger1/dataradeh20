{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "# from snowflake.sqlalchemy import URL\n",
    "import unidecode\n",
    "import zipfile\n",
    "import io\n",
    "import gzip\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input API Key and Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KEY = \"API_KEY\"\n",
    "SECRET = \"API_SECRET\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_request() function for connecting to Amplitude API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_request(endpoint, params = ()):\n",
    "    \"\"\"\n",
    "    Generic request function for making API requests to the amplitude API\n",
    "    \n",
    "    Example Endpoints: https://amplitude.zendesk.com/hc/en-us/articles/205469748-Dashboard-Rest-API-Export-Amplitude-Dashboard-Data\n",
    "    \"\"\"\n",
    "    res = requests.get('https://amplitude.com/api/2/'+endpoint, params=params, auth=(KEY, SECRET))\n",
    "    if res.status_code == 200:\n",
    "        return res.content\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample direct uses of make_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample use of make_request\n",
    "params = (\n",
    "    ('start', '20180921T07'),\n",
    "    ('end', '20180921T08')\n",
    ")\n",
    "\n",
    "\n",
    "data = make_request('events/list')\n",
    "# data = make_request('sessions/average', params)\n",
    "# data = make_request('annotations')\n",
    "# data = make_request('export', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = json.loads(data)\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame(out['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for Raw Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to check and clear current exported data\n",
    "def clear_raw_data(data_path='.'):\n",
    "    if '180337' in os.listdir(data_path):\n",
    "        shutil.rmtree(os.path.join(data_path,'180337'))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_zip(zip_fp):\n",
    "    \"\"\"\n",
    "    Loads compressed zip binary into a pandas DataFrame\n",
    "    \"\"\"\n",
    "    with gzip.GzipFile(zip_fp, 'r') as fin:\n",
    "        raw_data = fin.read()\n",
    "        \n",
    "    raw_data_split = str(raw_data)[2:].split('\\\\n')\n",
    "    parsed_data = [json.loads(i.replace('\\\\','')) for i in raw_data_split if len(i) > 1]\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_zip_dir(zip_dir):\n",
    "    \"\"\"\n",
    "    Loads all contents of a zip directory into a pandas DataFrame (via load_zip())\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for n, zip_fp in enumerate(os.listdir(zip_dir)):\n",
    "        loaded_percent = round(100.*(n+1)/len(os.listdir(zip_dir)),2)\n",
    "        print(f'Parsing data: {loaded_percent}% complete ...', end=\"\\r\")\n",
    "        dfs.append(load_zip(os.path.join(zip_dir,zip_fp)))\n",
    "    \n",
    "    print('Successfully parsed raw data. Concatenating and returning DF')\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Raw data extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data(start='20180921T07', end='20180921T08', clear_data=True):\n",
    "    \"\"\"\n",
    "    Extracts raw data, decompresses, and loads into pandas DataFrame\n",
    "    \n",
    "    Kwargs:\n",
    "      start -- <str> start date in 'YYYYMMDDTHH' format\n",
    "      end -- <str> end date in 'YYYYMMDDTHH' format\n",
    "      clear_data -- <bool> whether or not to clear the loaded data before exracting more (Default: True)\n",
    "      \n",
    "    Return:\n",
    "      parsed_data -- <pd.DataFrame> pandas DataFrame of parsed raw data\n",
    "    \"\"\"\n",
    "    if clear_data: \n",
    "        print('Clearing workspace ...')\n",
    "        clear_raw_data()\n",
    "        \n",
    "    params = (\n",
    "        ('start', start),\n",
    "        ('end', end)\n",
    "    )\n",
    "    print('Exporting data from API ...')\n",
    "    data = make_request('export', params)\n",
    "    z = zipfile.ZipFile(io.BytesIO(data))\n",
    "    z.extractall() \n",
    "    print('Successfully exported raw data. \\nParsing raw data ...')\n",
    "    parsed_data = load_zip_dir('180337')\n",
    "    return parsed_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = extract_data()\n",
    "out.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
